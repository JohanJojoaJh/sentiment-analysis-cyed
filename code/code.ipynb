{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "062in0DdOlRa"
      },
      "outputs": [],
      "source": [
        "#!pip install scikeras\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score,cohen_kappa_score, precision_score, f1_score,recall_score,make_scorer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, Dropout,LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"\"\n",
        "file_names = ['amazon_cells_labelled.txt', 'imdb_labelled.txt', 'yelp_labelled.txt']\n",
        "\n",
        "# Load data from multiple files\n",
        "dfs = []\n",
        "for file_name in file_names:\n",
        "    file_path = f\"{file_name}\"\n",
        "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['sentence', 'label'])\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate data from different files\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Task 2: Preprocess the text data\n",
        "# Tokenization, lowercasing, and removing stopwords using NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "df['processed_sentence'] = df['sentence'].apply(preprocess_text)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP0qJjk5Oqn8",
        "outputId": "57e291e2-f820-4a94-8c3d-0ecf1278ee22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               sentence  label  \\\n",
            "0     So there is no way for me to plug it in here i...      0   \n",
            "1                           Good case, Excellent value.      1   \n",
            "2                                Great for the jawbone.      1   \n",
            "3     Tied to charger for conversations lasting more...      0   \n",
            "4                                     The mic is great.      1   \n",
            "...                                                 ...    ...   \n",
            "2743  I think food should have flavor and texture an...      0   \n",
            "2744                           Appetite instantly gone.      0   \n",
            "2745  Overall I was not impressed and would not go b...      0   \n",
            "2746  The whole experience was underwhelming, and I ...      0   \n",
            "2747  Then, as if I hadn't wasted enough of my life ...      0   \n",
            "\n",
            "                                     processed_sentence  \n",
            "0                       way plug us unless go converter  \n",
            "1                             good case excellent value  \n",
            "2                                         great jawbone  \n",
            "3           tied charger conversations lasting problems  \n",
            "4                                             mic great  \n",
            "...                                                 ...  \n",
            "2743                  think food flavor texture lacking  \n",
            "2744                            appetite instantly gone  \n",
            "2745                    overall impressed would go back  \n",
            "2746  whole experience underwhelming think go ninja ...  \n",
            "2747  wasted enough life poured salt wound drawing t...  \n",
            "\n",
            "[2748 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_sentence'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "dummy_clf = make_pipeline(CountVectorizer(), DummyClassifier(strategy='most_frequent'))\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "y_pred_dummy = dummy_clf.predict(X_test)\n",
        "\n",
        "# Evaluate DummyClassifier performance\n",
        "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
        "precision_dummy = precision_score(y_test, y_pred_dummy)\n",
        "recall_dummy = recall_score(y_test, y_pred_dummy)\n",
        "f1_dummy = f1_score(y_test, y_pred_dummy)\n",
        "\n",
        "print(\"DummyClassifier Performance:\")\n",
        "print(f\"Accuracy: {accuracy_dummy}\")\n",
        "print(f\"Precision: {precision_dummy}\")\n",
        "print(f\"Recall: {recall_dummy}\")\n",
        "print(f\"F1-score: {f1_dummy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed_lnUyIP8FK",
        "outputId": "4ade2921-79d0-45db-f01a-01f652e12bfe"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier Performance:\n",
            "Accuracy: 0.4709090909090909\n",
            "Precision: 0.4709090909090909\n",
            "Recall: 1.0\n",
            "F1-score: 0.6402966625463535\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_sentence'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "max_words = 10000\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 128, input_length=max_len))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(X_train_pad, y_train_encoded, validation_split=0.2,\n",
        "                    epochs=25, batch_size=128)\n",
        "\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy_rnn = accuracy_score(y_test_encoded, y_pred_binary)\n",
        "precision_rnn = precision_score(y_test_encoded, y_pred_binary)\n",
        "recall_rnn = recall_score(y_test_encoded, y_pred_binary)\n",
        "f1_rnn = f1_score(y_test_encoded, y_pred_binary)\n",
        "\n",
        "print(\"RNN Performance:\")\n",
        "print(f\"Accuracy: {accuracy_rnn}\")\n",
        "print(f\"Precision: {precision_rnn}\")\n",
        "print(f\"Recall: {recall_rnn}\")\n",
        "print(f\"F1-score: {f1_rnn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzHy3yC0RSBk",
        "outputId": "d955176f-f629-4f1f-ad9d-2338ca988d27"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "14/14 [==============================] - 3s 103ms/step - loss: 0.6994 - accuracy: 0.5114 - val_loss: 0.6829 - val_accuracy: 0.5386\n",
            "Epoch 2/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.6236 - accuracy: 0.7196 - val_loss: 0.6693 - val_accuracy: 0.6273\n",
            "Epoch 3/25\n",
            "14/14 [==============================] - 2s 119ms/step - loss: 0.5255 - accuracy: 0.8663 - val_loss: 0.6569 - val_accuracy: 0.6364\n",
            "Epoch 4/25\n",
            "14/14 [==============================] - 2s 111ms/step - loss: 0.3968 - accuracy: 0.9158 - val_loss: 0.6365 - val_accuracy: 0.6477\n",
            "Epoch 5/25\n",
            "14/14 [==============================] - 2s 118ms/step - loss: 0.2857 - accuracy: 0.9556 - val_loss: 0.6103 - val_accuracy: 0.6545\n",
            "Epoch 6/25\n",
            "14/14 [==============================] - 2s 137ms/step - loss: 0.1879 - accuracy: 0.9699 - val_loss: 0.6006 - val_accuracy: 0.6841\n",
            "Epoch 7/25\n",
            "14/14 [==============================] - 2s 111ms/step - loss: 0.1265 - accuracy: 0.9818 - val_loss: 0.5920 - val_accuracy: 0.6818\n",
            "Epoch 8/25\n",
            "14/14 [==============================] - 2s 138ms/step - loss: 0.0898 - accuracy: 0.9846 - val_loss: 0.6070 - val_accuracy: 0.6864\n",
            "Epoch 9/25\n",
            "14/14 [==============================] - 2s 161ms/step - loss: 0.0711 - accuracy: 0.9858 - val_loss: 0.6091 - val_accuracy: 0.7136\n",
            "Epoch 10/25\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.6147 - val_accuracy: 0.7205\n",
            "Epoch 11/25\n",
            "14/14 [==============================] - 2s 120ms/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.6196 - val_accuracy: 0.7295\n",
            "Epoch 12/25\n",
            "14/14 [==============================] - 2s 115ms/step - loss: 0.0430 - accuracy: 0.9909 - val_loss: 0.6163 - val_accuracy: 0.7091\n",
            "Epoch 13/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.6323 - val_accuracy: 0.7136\n",
            "Epoch 14/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 0.0323 - accuracy: 0.9932 - val_loss: 0.6442 - val_accuracy: 0.7159\n",
            "Epoch 15/25\n",
            "14/14 [==============================] - 1s 82ms/step - loss: 0.0274 - accuracy: 0.9943 - val_loss: 0.6554 - val_accuracy: 0.7023\n",
            "Epoch 16/25\n",
            "14/14 [==============================] - 1s 80ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.6660 - val_accuracy: 0.7136\n",
            "Epoch 17/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 0.0235 - accuracy: 0.9954 - val_loss: 0.6808 - val_accuracy: 0.7091\n",
            "Epoch 18/25\n",
            "14/14 [==============================] - 1s 72ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.6932 - val_accuracy: 0.7045\n",
            "Epoch 19/25\n",
            "14/14 [==============================] - 1s 81ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.7091 - val_accuracy: 0.6955\n",
            "Epoch 20/25\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.7221 - val_accuracy: 0.7000\n",
            "Epoch 21/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.7362 - val_accuracy: 0.7000\n",
            "Epoch 22/25\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.7512 - val_accuracy: 0.6977\n",
            "Epoch 23/25\n",
            "14/14 [==============================] - 2s 120ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.7585 - val_accuracy: 0.6955\n",
            "Epoch 24/25\n",
            "14/14 [==============================] - 2s 117ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.7707 - val_accuracy: 0.6955\n",
            "Epoch 25/25\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 0.0135 - accuracy: 0.9943 - val_loss: 0.7794 - val_accuracy: 0.6955\n",
            "18/18 [==============================] - 0s 9ms/step\n",
            "RNN Performance:\n",
            "Accuracy: 0.7054545454545454\n",
            "Precision: 0.6816479400749064\n",
            "Recall: 0.7027027027027027\n",
            "F1-score: 0.6920152091254753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_classifier = KerasClassifier(build_fn=model, epochs=25, batch_size=128, verbose=0)\n",
        "\n",
        "# Definir los parámetros a buscar\n",
        "param_grid = {\n",
        "    'optimizer': [\"adam\",\"sgd\" ,\"rmsprop\" ],\n",
        "    'loss': [\"binary_crossentropy\"],\n",
        "    'activation': [\"tanh\", \"relu\",\"sigmoid\"],\n",
        "    \"layers\":[[20],[40,20], [45, 30, 15]],\n",
        "}\n",
        "\n",
        "# Crear el objeto GridSearchCV\n",
        "grid = GridSearchCV(estimator=rnn_classifier, param_grid=param_grid, scoring='accuracy', cv=3)\n",
        "\n",
        "# Preprocesar los datos nuevamente para asegurarse de que todo está en orden\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Ejecutar la búsqueda de hiperparámetros\n",
        "grid_result = grid.fit(X_train_pad, y_train_encoded)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Best Accuracy: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Accuracy: {mean} (±{stdev}) with: {param}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "DBJsGCUTbr_4",
        "outputId": "7d3f715e-2805-473b-a38f-075fcbaecaf7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-965e5ed6f1cd>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Ejecutar la búsqueda de hiperparámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Imprimir los resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/_saving_utils.py\u001b[0m in \u001b[0;36mdeepcopy_model\u001b[0;34m(model, memo)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeepcopy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/_saving_utils.py\u001b[0m in \u001b[0;36munpack_keras_model\u001b[0;34m(packed_keras_model)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'build'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmYVynk3kIly",
        "outputId": "8612fb5f-c6e8-40e3-e816-029812e85196"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " simple_rnn_12 (SimpleRNN)   (None, 64)                12352     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1292417 (4.93 MB)\n",
            "Trainable params: 1292417 (4.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_sentence'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "max_words = 10000\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 128, input_length=max_len))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(X_train_pad, y_train_encoded, validation_split=0.2,\n",
        "                    epochs=25, batch_size=128)\n",
        "\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy_rnn = accuracy_score(y_test_encoded, y_pred_binary)\n",
        "precision_rnn = precision_score(y_test_encoded, y_pred_binary)\n",
        "recall_rnn = recall_score(y_test_encoded, y_pred_binary)\n",
        "f1_rnn = f1_score(y_test_encoded, y_pred_binary)\n",
        "kappa_rnn=cohen_kappa_score(y_test_encoded,y_pred_binary)\n",
        "\n",
        "print(\"RNN Performance:\")\n",
        "print(f\"Accuracy: {accuracy_rnn}\")\n",
        "print(f\"Precision: {precision_rnn}\")\n",
        "print(f\"Recall: {recall_rnn}\")\n",
        "print(f\"F1-score: {f1_rnn}\")\n",
        "print(f\"Kappa-score: {kappa_rnn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDPYa-wWhb6P",
        "outputId": "877262c5-b94e-4255-b080-afe34267f158"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "14/14 [==============================] - 4s 85ms/step - loss: 0.6962 - accuracy: 0.5165 - val_loss: 0.6801 - val_accuracy: 0.5636\n",
            "Epoch 2/25\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.6428 - accuracy: 0.6559 - val_loss: 0.6597 - val_accuracy: 0.6227\n",
            "Epoch 3/25\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5555 - accuracy: 0.8464 - val_loss: 0.6411 - val_accuracy: 0.6182\n",
            "Epoch 4/25\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.4387 - accuracy: 0.9073 - val_loss: 0.5788 - val_accuracy: 0.7250\n",
            "Epoch 5/25\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.3815 - accuracy: 0.8561 - val_loss: 0.5513 - val_accuracy: 0.7182\n",
            "Epoch 6/25\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.2408 - accuracy: 0.9465 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.1902 - accuracy: 0.9573 - val_loss: 0.5155 - val_accuracy: 0.7455\n",
            "Epoch 8/25\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.1379 - accuracy: 0.9710 - val_loss: 0.5095 - val_accuracy: 0.7568\n",
            "Epoch 9/25\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.1042 - accuracy: 0.9772 - val_loss: 0.5429 - val_accuracy: 0.7250\n",
            "Epoch 10/25\n",
            "14/14 [==============================] - 2s 108ms/step - loss: 0.1718 - accuracy: 0.9391 - val_loss: 0.5904 - val_accuracy: 0.7159\n",
            "Epoch 11/25\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 0.5598 - val_accuracy: 0.7227\n",
            "Epoch 12/25\n",
            "14/14 [==============================] - 1s 72ms/step - loss: 0.0677 - accuracy: 0.9812 - val_loss: 0.5518 - val_accuracy: 0.7455\n",
            "Epoch 13/25\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.0488 - accuracy: 0.9886 - val_loss: 0.5630 - val_accuracy: 0.7386\n",
            "Epoch 14/25\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 0.0409 - accuracy: 0.9898 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.6080 - val_accuracy: 0.7227\n",
            "Epoch 16/25\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.6170 - val_accuracy: 0.7295\n",
            "Epoch 17/25\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 0.1030 - accuracy: 0.9602 - val_loss: 0.8894 - val_accuracy: 0.6682\n",
            "Epoch 18/25\n",
            "14/14 [==============================] - 1s 71ms/step - loss: 0.0955 - accuracy: 0.9653 - val_loss: 0.8032 - val_accuracy: 0.6977\n",
            "Epoch 19/25\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.7080 - val_accuracy: 0.6955\n",
            "Epoch 20/25\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0300 - accuracy: 0.9954 - val_loss: 0.7418 - val_accuracy: 0.7273\n",
            "Epoch 21/25\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.7659 - val_accuracy: 0.7250\n",
            "Epoch 22/25\n",
            "14/14 [==============================] - 1s 71ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.7661 - val_accuracy: 0.7182\n",
            "Epoch 23/25\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.7246 - val_accuracy: 0.7114\n",
            "Epoch 24/25\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.8188 - val_accuracy: 0.7227\n",
            "Epoch 25/25\n",
            "14/14 [==============================] - 1s 97ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.8162 - val_accuracy: 0.7205\n",
            "18/18 [==============================] - 0s 8ms/step\n",
            "RNN Performance:\n",
            "Accuracy: 0.7290909090909091\n",
            "Precision: 0.7217741935483871\n",
            "Recall: 0.6911196911196911\n",
            "F1-score: 0.7061143984220907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_sentence'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "max_words = 10000\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "model_lstm  = Sequential()\n",
        "model_lstm .add(Embedding(max_words, 128, input_length=max_len))\n",
        "model_lstm .add(LSTM(64))\n",
        "model_lstm .add(Dropout(0.5))\n",
        "model_lstm .add(Dense(1, activation='softmax'))\n",
        "\n",
        "\n",
        "model_lstm .compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model_lstm .fit(X_train_pad, y_train_encoded, validation_split=0.2,\n",
        "                    epochs=25, batch_size=128)\n",
        "\n",
        "y_pred = model_lstm.predict(X_test_pad)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy_lstm = accuracy_score(y_test_encoded, y_pred_binary)\n",
        "precision_lstm = precision_score(y_test_encoded, y_pred_binary)\n",
        "recall_lstm = recall_score(y_test_encoded, y_pred_binary)\n",
        "f1_lstm = f1_score(y_test_encoded, y_pred_binary)\n",
        "kappa_lstm=cohen_kappa_score(y_test_encoded,y_pred_binary)\n",
        "\n",
        "print(\"LSTM Performance:\")\n",
        "print(f\"Accuracy: {accuracy_lstm}\")\n",
        "print(f\"Precision: {precision_lstm}\")\n",
        "print(f\"Recall: {recall_lstm}\")\n",
        "print(f\"F1-score: {f1_lstm}\")\n",
        "print(f\"Kappa-score: {kappa_lstm}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpNzzRICl3AV",
        "outputId": "6758a13e-54a2-4926-e724-12cb6d35bf6b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "14/14 [==============================] - 10s 374ms/step - loss: 0.6914 - accuracy: 0.5142 - val_loss: 0.6881 - val_accuracy: 0.5068\n",
            "Epoch 2/25\n",
            "14/14 [==============================] - 3s 209ms/step - loss: 0.6747 - accuracy: 0.5142 - val_loss: 0.6714 - val_accuracy: 0.5068\n",
            "Epoch 3/25\n",
            "14/14 [==============================] - 5s 324ms/step - loss: 0.6178 - accuracy: 0.5142 - val_loss: 0.6155 - val_accuracy: 0.5068\n",
            "Epoch 4/25\n",
            "14/14 [==============================] - 3s 202ms/step - loss: 0.4586 - accuracy: 0.5142 - val_loss: 0.5362 - val_accuracy: 0.5068\n",
            "Epoch 5/25\n",
            "14/14 [==============================] - 3s 212ms/step - loss: 0.2868 - accuracy: 0.5142 - val_loss: 0.4991 - val_accuracy: 0.5068\n",
            "Epoch 6/25\n",
            "14/14 [==============================] - 3s 205ms/step - loss: 0.1758 - accuracy: 0.5142 - val_loss: 0.5329 - val_accuracy: 0.5068\n",
            "Epoch 7/25\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.1279 - accuracy: 0.5142 - val_loss: 0.6174 - val_accuracy: 0.5068\n",
            "Epoch 8/25\n",
            "14/14 [==============================] - 4s 244ms/step - loss: 0.1229 - accuracy: 0.5142 - val_loss: 0.5145 - val_accuracy: 0.5068\n",
            "Epoch 9/25\n",
            "14/14 [==============================] - 3s 204ms/step - loss: 0.1225 - accuracy: 0.5142 - val_loss: 0.5456 - val_accuracy: 0.5068\n",
            "Epoch 10/25\n",
            "14/14 [==============================] - 3s 200ms/step - loss: 0.0733 - accuracy: 0.5142 - val_loss: 0.6321 - val_accuracy: 0.5068\n",
            "Epoch 11/25\n",
            "14/14 [==============================] - 3s 254ms/step - loss: 0.0547 - accuracy: 0.5142 - val_loss: 0.7256 - val_accuracy: 0.5068\n",
            "Epoch 12/25\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0763 - accuracy: 0.5142 - val_loss: 0.5903 - val_accuracy: 0.5068\n",
            "Epoch 13/25\n",
            "14/14 [==============================] - 3s 209ms/step - loss: 0.0990 - accuracy: 0.5142 - val_loss: 0.6138 - val_accuracy: 0.5068\n",
            "Epoch 14/25\n",
            "14/14 [==============================] - 3s 204ms/step - loss: 0.0731 - accuracy: 0.5142 - val_loss: 0.6339 - val_accuracy: 0.5068\n",
            "Epoch 15/25\n",
            "14/14 [==============================] - 3s 205ms/step - loss: 0.0556 - accuracy: 0.5142 - val_loss: 0.6652 - val_accuracy: 0.5068\n",
            "Epoch 16/25\n",
            "14/14 [==============================] - 5s 354ms/step - loss: 0.0450 - accuracy: 0.5142 - val_loss: 0.7017 - val_accuracy: 0.5068\n",
            "Epoch 17/25\n",
            "14/14 [==============================] - 3s 199ms/step - loss: 0.0368 - accuracy: 0.5142 - val_loss: 0.7373 - val_accuracy: 0.5068\n",
            "Epoch 18/25\n",
            "14/14 [==============================] - 3s 205ms/step - loss: 0.0337 - accuracy: 0.5142 - val_loss: 0.7695 - val_accuracy: 0.5068\n",
            "Epoch 19/25\n",
            "14/14 [==============================] - 3s 216ms/step - loss: 0.0320 - accuracy: 0.5142 - val_loss: 0.8048 - val_accuracy: 0.5068\n",
            "Epoch 20/25\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0291 - accuracy: 0.5142 - val_loss: 0.8399 - val_accuracy: 0.5068\n",
            "Epoch 21/25\n",
            "14/14 [==============================] - 4s 244ms/step - loss: 0.0282 - accuracy: 0.5142 - val_loss: 0.8733 - val_accuracy: 0.5068\n",
            "Epoch 22/25\n",
            "14/14 [==============================] - 3s 208ms/step - loss: 0.0285 - accuracy: 0.5142 - val_loss: 0.8640 - val_accuracy: 0.5068\n",
            "Epoch 23/25\n",
            "14/14 [==============================] - 3s 213ms/step - loss: 0.0256 - accuracy: 0.5142 - val_loss: 0.8684 - val_accuracy: 0.5068\n",
            "Epoch 24/25\n",
            "14/14 [==============================] - 3s 253ms/step - loss: 0.0228 - accuracy: 0.5142 - val_loss: 0.8972 - val_accuracy: 0.5068\n",
            "Epoch 25/25\n",
            "14/14 [==============================] - 4s 287ms/step - loss: 0.0229 - accuracy: 0.5142 - val_loss: 0.9325 - val_accuracy: 0.5068\n",
            "18/18 [==============================] - 2s 18ms/step\n",
            "LSTM Performance:\n",
            "Accuracy: 0.4709090909090909\n",
            "Precision: 0.4709090909090909\n",
            "Recall: 1.0\n",
            "F1-score: 0.6402966625463535\n",
            "Kappa-score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_classifier = KerasClassifier(build_fn=model_lstm, epochs=25, batch_size=128, verbose=0)\n",
        "\n",
        "# Definir los parámetros a buscar\n",
        "param_grid = {\n",
        "    'optimizer': [\"adam\",\"sgd\" ,\"rmsprop\" ],\n",
        "    'loss': [\"binary_crossentropy\"],\n",
        "}\n",
        "\n",
        "# Crear el objeto GridSearchCV\n",
        "grid = GridSearchCV(estimator=lstm_classifier, param_grid=param_grid, scoring='accuracy', cv=3)\n",
        "\n",
        "# Preprocesar los datos nuevamente para asegurarse de que todo está en orden\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Ejecutar la búsqueda de hiperparámetros\n",
        "grid_result = grid.fit(X_train_pad, y_train_encoded)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Best Accuracy: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Accuracy: {mean} (±{stdev}) with: {param}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n9YDb8nAGe",
        "outputId": "be5161d3-9c6f-485d-ec81-debe2245d5ca"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.5127386516971201 using {'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
            "Accuracy: 0.5127386516971201 (±0.00031365116394637787) with: {'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
            "Accuracy: 0.5127386516971201 (±0.00031365116394637787) with: {'loss': 'binary_crossentropy', 'optimizer': 'sgd'}\n",
            "Accuracy: 0.5127386516971201 (±0.00031365116394637787) with: {'loss': 'binary_crossentropy', 'optimizer': 'rmsprop'}\n"
          ]
        }
      ]
    }
  ]
}